\section{Statistics \& Parameters}

In this section, we discuss the process of going from sky maps at different frequencies---or, in light
of the previous section, foreground-cleaned CMB maps and an estimate of foreground residuals---to
post-map products such as angular power spectra, estimates of lensing potential $\phi$, and finally
cosmological parameters, as well as covariance estimates for all of these quantities. We briefly describe
the current practice for this process, then we address specific challenges anticipated in the \cmbexp\ era.

\subsection{Current practice}
\label{se:current}
Early measurements of CMB temperature anisotropy, with comparatively few map pixels or angular modes
measured, often used maximum-likelihood methods to produce maps of the sky (e.g., \cite{Wright:1996dk}) and
either a direct evaluation of the full likelihood or a quadratic approximation to that likelihood (e.g., \cite{Bond:1998zw}) to go from 
maps to angular power spectra. With the advent of the WMAP and Planck space 
missions, which would map the entire sky at sub-degree resolution, it became apparent that computing
resources could not compete with the $\mathcal{O}({\cal N}^3)$ scaling of the full-likelihood approach 
(e.g., \cite{Borrill:1998tn}). The solution for power spectrum analysis
that has been adopted by most current CMB experiments is a
Monte-Carlo-based approach advocated in \cite{Hivon:2001jp}. In this approach, a biased estimate of
the angular power spectrum of the data is obtained by simply binning and averaging the square 
of the spherical harmonic transform of the sky map. That estimate (known as the 
``pseudo-$C_\ell$ spectrum'') is related to the unbiased 
estimate that would be obtained in a maximum-likelihood procedure through the combined effect
of noise bias, sky windowing, and any filtering applied to the data before or after mapmaking
(including the effects of instrument beam and pixelization). These effects are estimated by ``observing''
and analyzing simulated data and constructing a matrix describing their net influence on simulated data. 
This matrix is inverted, and the inverse matrix is applied to the pseudo-$C_\ell$s to produce the 
final data product. Some version of this Monte-Carlo treatment is likely to be 
adopted for \cmbexp. 

Pseudo-$C_\ell$ methods are also now commonly used in analysis of CMB polarization anisotropy
\cite{Aghanim:2015xee,Naess:2014wtr,Crites:2014prc}. An added complication in polarization analyses is that 
pseudo-$C_\ell$ methods do not cleanly separate $E$ and $B$ modes (e.g., \cite{Challinor:2005jy}).
``Pure'' $B$-mode estimators can be constructed that suppress the spurious $B$-mode contribution
from estimating $E$ and $B$ on a cut sky with pseudo-$C_\ell$ methods \cite{Smith:2005gi}), but 
other analysis steps (such as particular choices of filtering) can produce spurious $B$ modes that
are immune to the pure estimators \cite{Keisler:2015hfa}. These can also be dealt with using Monte-Carlo
methods, either by estimating the statistical bias to the final $B$-mode spectrum or by constructing
a matrix representing the effect of any analysis steps on the true sky \cite{Ade:2014xna}. The latter
approach involves constructing an ${\cal N}_\mathrm{pixel}$-by-${\cal N}_\mathrm{pixel}$ matrix, equal in size to the 
full pixel-pixel covariance, and will not be feasible for high-resolution \cmbexp\ data but could be 
used in analyzing lower-resolution data.

In addition to the two-point function of CMB maps, higher-order statistics of the maps have recently 
been of great interest to the community. In particular, the four-point function encodes the effect of 
gravitational lensing, and estimators can be constructed to go from CMB temperature and polarization
maps to estimates of CMB lensing $\phi$ and the associated covariance (e.g., \cite{Hu:2001kj,Okamoto:2003zw}).
These quadratic estimators are the first step in an iterative estimation of the true likelihood, and in
the weak-lensing limit they are nearly optimal; as a result, they remain the state of the art for estimating
the large-scale $\phi$ from CMB lensing (e.g., \cite{Ade:2013lta}). For \cmbexp\ sensitivity levels, 
it is possible that further gains can be made with more iterations (see Section \ref{delens}).
Even with multiple steps, the computational burden involved
in this step of the analysis is unlikely to be significantly greater for \cmbexp\ than for Planck.

An additional post-map product of interest for \cmbexp\ is the location and properties of compact
sources, in particular clusters of galaxies identified through the thermal SZ effect. The standard 
practice for extracting SZ clusters from multifrequency millimeter-wave maps is through the application
of a Fourier-domain spatial-spectral filter \cite{Melin:2006qq}.
The computational effort involved in this step is small compared to the estimation of power spectra 
and higher-order correlations, and the algorithms are well-developed and fully implemented for 
multi-frequency data sets (e.g., \cite{Ade:2013skr,Bleem:2014iim})---however, the cluster density
could be high enough in \cmbexp\ data that approaches more sophisticated than the simple matched
filter (e.g., \cite{Pierpaoli:2004bp}) could be required to maximize cluster yield.

The final step in the analysis of a CMB data set is the estimation of cosmological parameters from
the various post-map statistics discussed above.
% (the second step in Figure \ref{fig_sp}). 
This involves estimating the likelihood of the data
given a model parameterized by the standard six $\Lambda$CDM parameters, possible extensions
of the cosmological model, and any nuisance parameters involving the instrument, foregrounds, and
other sources of systematic uncertainty. The current industry standard for this part of the analysis are
Monte-Carlo Markoalv-Chain (MCMC) methods, in particular the implementation in CosmoMC
\cite{Lewis:2002ah}, and it is expected that \cmbexp\ will use similar methods. 

\subsection{Challenges}
\label{se:challenges}
There will be several 
aspects of the \cmbexp\ dataset that will necessitate going beyond what past analyses
have done at the post-map step. First of all, the data from several different telescopes and cameras will need
to be combined in as lossless a fashion as possible---such that combining at the parameters stage
may be sub-optimal.
Further, as shown by \cite{Ade:2015tva}, foregrounds cannot be ignored in the 
estimation of the $B$-mode power spectrum, even in the cleanest parts of the sky and in the 
least contaminated observing bands. Foreground modeling will be used to mitigate the contamination,
but there will be foreground residuals (both from noise and imperfect modeling), and these need
to be properly characterized and accounted for in parameter extraction. 
Similarly, algorithms to separate the contributions to the $B$-mode power spectrum from a background of gravitational
waves and from lensing of $E$ modes (so-called ``de-lensing'', see the Section \ref{delens} for 
details) will leave an uncertain level of lensing residuals in the primordial $B$-mode spectrum, and
this residual will need to be treated properly. Finally, for information from angular power spectra
and lensing potential $\phi$ to be properly combined, the covariance between the two-point and
four-point functions of the CMB needs to be taken into account.

We treat each of the following challenges individually in the sections below:
\begin{itemize}
\item{The combination of data from different telescopes and cameras (with different heritage 
and observation/analysis techniques) without significant loss of information.}
\item{The impact of uncertainties in foreground modeling on cosmological parameters, particularly the tensor-to-scalar ratio $r$.}
\item{The covariance between different observables (for example the lensed CMB power spectrum and the reconstructed lensing potential power spectrum).}
\item{The impact of delensing---the separation of the gravitational lensing signal and the primordial $B$-mode signal, lowering the effective lensing background---and lensing residuals on cosmological parameters.} 
\end{itemize}


\subsubsection{Combining different data sets}
\label{se:combine}
At what stage in the analysis does it make the most sense to combine data from different experimental platforms? 
One possibility is to estimate
angular power spectra or even cosmological parameters from every data set individually and combine them at that stage. This would
be computationally efficient but sub-optimal from a sensitivity standpoint unless every experiment
covered fully independent patches of the sky. For any overlap between data sets, combining at
the map or time-ordered data stage (adding before squaring) will lead to lower final uncertainties
than combining at the power spectrum stage (squaring before adding). Of course, the earlier in the analysis
we choose to combine data, the more work it will be to standardize the data between experimental platforms---the
time-ordered data is generally quite instrument-specific, the maps less so, etc. The trade-off between
maximizing constraining power and possibly placing undue burdens on the individual  
pipelines will need to be balanced in answering this question.
Furthermore, the frequency coverage may not be identical across the individual experimental platforms.
In this case, combining data at the stage of independent frequency-band maps will result in
different sky coverage at different frequencies; combining data at the stage of foreground-cleaned
CMB maps will result in different foreground residuals and noise levels in different parts of the sky.
These factors must also be balanced in the decision of when to combine data.

\subsubsection{Foreground-related uncertainty on cosmological parameters}
\label{se:paramforeg}

% do frequency-map cross-spectra and fit for foregrounds or do component separation and 
% parameterize foreground residuals. either way, what parameterization? refer to comp sep
% and sky modeling sections.

To separate the CMB signal from the contaminating signals of Galactic and extragalactic foregrounds, 
data from multiple bands will be combined, either 
in a cross-spectrum analysis or, as detailed in Section \ref{sec:compsep}, by making linear 
combinations of maps in different bands to produce a ``pure-CMB'' map for power spectrum estimation.
In either case, an underlying model of foreground behavior is assumed---even if that model is simply
an assumption regarding the level to which the spectral behavior of foregrounds varies over the sky.
There are two challenges related to uncertainties in foreground modeling: one statistical and one
systematic. The statistical issue is simply how to propagate the statistical uncertainty on the foreground 
model to uncertainties on cosmological parameters. In explicitly parameterized foreground models, 
this happens automatically through the covariance resulting from the fit. For non-parametric models,
this covariance can be assessed through Monte Carlo methods, but making many independent 
realizations of large-scale Galactic foregrounds is problematic because of the strongly non-Gaussian
behavior of these foregreounds.

Perhaps more importantly, 
any model of foreground behavior is by definition imperfect, and the resulting component separation
or frequency-cross-spectrum fit will have systematic leakage between the foreground and CMB components.
At the sensitivity levels attainable by \cmbexp, these residuals have the potential to dominate the
error budget on cosmological parameters and, more troublingly, to significantly bias the best-fit 
parameter values if they are not properly taken into account.

Section~\ref{sec:skymodel} discusses the baseline plan for, and challenges involved in, modeling
Galactic and extragalactic foregrounds. It is possible that more information will be needed---from 
Stage-3 experiments, or from a possible dedicated, balloon-borne CMB foreground mission---before
we can confidently assess the level to which foregrounds will limit the final parameter constraints
from \cmbexp\ and how flexible we will need to make the underlying foreground models that 
inform component separation and parameter extraction. 

\subsubsection{CMB lensing covariances for \cmbexp }
\label{se:covs}

The measured lensing power spectrum is given by a four-point function of the lensed CMB. 
This is not statistically independent from the lensed CMB two-point function, because both depend on the same observed, lensed CMB maps. 
As a consequence, measured lensing power spectra and lensed CMB power spectra may be correlated. 
This correlation should be taken into account when combining these measurements to avoid spurious double counting of information. 
For the specific case of Planck this correlation is negligible \cite{Schmittfull:2013uea}. 
However, the level of correlation depends on experiment specifications and the multipole range where power spectra have high signal-to-noise. 
The correlation should thus be included in analyses that combine two- and four-point measurements unless it is known to be negligible for a specific experiment.
\\

The forecasted noise level for CMB-S4 is much lower than the noise level for Planck, and the reconstruction of the lensing potential power spectrum will come from a mixture of temperature and polarization data.
In this context, modelling the correlations only in the case of temperature is not accurate enough.
Instead, a minimum variance lensing estimator out of all the measured quadratic pairs needs to be considered, and contributions arising from all couplings of the CMB six-point function would need to be modelled.
There are a number of further challenges involving the covariance of CMB N-point functions, which we do not treat in detail here but are addressed in \cite{Peloton:prep} for example. 
\\

\cite{Schmittfull:2013uea} and \cite{Peloton:prep} identified three main contributions to the cross-covariance: The noise contribution arising because fluctuations of the unlensed CMB and instrumental noise change both the Gaussian reconstruction noise $N^{(0)}$ and the CMB power spectra;
the signal contribution from the cosmic variance fluctuations of the true lensing potential (i.e.~fluctuations of matter along the line of sight); and contributions coming from the connected trispectrum part of the CMB six-point function.
Those contributions have been modelled with high precision and agree well with simulations.
The noise contribution is not present if the Gaussian reconstruction bias $N^{(0)}$ is subtracted in a realization-dependent way using the measured CMB power spectrum in our universe (see e.g.~\cite{Hanson:2010rp,Schmittfull:2013uea}).
However for an experiment such as CMB-S4, the last two contributions contribute the most to the correlation between lensing power spectra and lensed CMB power spectra, reaching few tens of percent in some cases.
The signal covariance could in principle also be avoided by delensing CMB power spectra with the estimated lensing reconstruction by mimicking the realization-dependent technique as shown in \cite{Schmittfull:2013uea}, or by applying more advanced delensing methods as described in Section \ref{delens}.
In addition to the cross-covariance between two-point and four-point functions of the CMB, these quantities can each have non-trivial auto-covariances which can again be modeled as shown in e.g.~\cite{Smith:2005ue,Smith:2006nk,Li:2006pu,BenoitLevy:2012va,Schmittfull:2013uea,Peloton:prep}. 
However we want to emphasise that the discussion above applies to the standard quadratic lensing reconstruction estimators, and the situation may be different for iterative or maximum-likelihood lensing estimators \cite{Hirata:2002jy}.

\subsubsection{Delensing}
For noise levels below $\Delta_P \simeq 5 \mu$K-arcmin (after foreground cleaning),  the dominant source of effective noise in the search for primordial $B$ modes is the fluctuation induced by the lensing of $E$ modes from recombination.  This signal has a well-understood amplitude, and unlike many other sources of astrophysical fluctuation in the map, it cannot be removed with multifrequency data.  Instead it must be removed either using map-level estimates of both the primordial $E$-mode maps and the CMB lensing potential $\phi$ or using a prediction for the lensing $B$-mode spectrum. The latter approach necessarily leaves some cosmic variance residual of the lensing signal after cleaning, while the former can in principle result in nearly perfect cleaning, so we will concentrate on that approach here.

%As discussed in the dedicated CMB lensing chapter, delensing will also be a crucial portion of the reconstruction of the CMB lensing field.  This is because at low noise levels a quadratic reconstruction of lensing using the $EB$ estimator \cite{Hu:2001kj} can be improved upon by cleaning the CMB maps of the lens-induced $B$-mode fluctuations, and then performing lens reconstruction again.  In effect, the quadratic estimate of \cite{Hu:2001kj} is effectively the first step in an iterative scheme to find the maximum-likelihood solution for the lensing and primordial fields \cite{Hirata:2002jy}.  CMB maps cleaned of the lensing signals will thus likely be produced as part of the CMB lensing analysis procedure.

Even in the map-level approach, the finite noise in the \cmbexp\ survey will lead to residual lensing $B$ modes which cannot be removed and will act as a noise floor for studying $B$ modes from tensors.  The amplitude of these residual lensed $B$ modes are discussed in Section \ref{delens} as a function of the angular resolution and the noise level of the S4 survey; in particular, it is crucial to have high-angular-resolution maps in order to measure the small-scale $E$- and $B$-mode fluctuations needed for the $EB$ quadratic lensing estimator.

The concerns with the delensing procedure are similar to those for measuring the lensing power spectrum. The impact of polarized dust and synchrotron emission from the Galaxy, and the impact of polarized point sources on small scales on the lensing reconstruction are addressed in Section~\ref{systAst}. Left untreated the effects may be large; however the use of  multi-frequency data together with the application of dedicated point-source estimators can mitigate these effects.

Another question to be answered for delensing in \cmbexp\ is what to use as the estimate of lensing $\phi$.
Rather than using an estimate of the CMB lensing field obtained from the CMB itself, it is also possible to use other tracers of large-scale structure which are correlated with  CMB lensing \cite{Smith:2010gu}.  In particular the dusty, star-forming galaxies that comprise the cosmic infrared background (CIB) are strongly correlated with CMB lensing, due to their redshift distribution which peaks near $z \sim 2$ \cite{Sherwin:2015baa,Simard:2014aqa}.  The level of correlation is approximately $80\%$ \cite{Ade:2013lta} and can in principle be improved using multifrequency maps of the CIB which select different emission redshifts \cite{Sherwin:2015baa}.  

Lensing of the CMB can also impact the measurement of features of the CMB power spectrum on small scales, in particular the CMB damping scale and the precise location of the acoustic peaks in harmonic space.  Delensing can therefore improve not just our measurement of primordial $B$ modes but also constraints on parameters that affect the damping tail and peak location.
%Effects that can change these observables include changes in 
This includes parameters such as the effective number of neutrino species,  the primordial helium fraction, and running of the spectral index of fluctuations.  Using completely unlensed CMB spectra, rather than lensed spectra, can improve constraints on these parameters. (For example, \cite{Baumann:2015rya} find a 20\% improvement on $\sigma(\neff)$ relative to no delensing.)  While the delensing procedure will not completely recover the unlensed CMB fluctuations for the S4 experiment, the low noise levels will enable the primordial CMB fluctuations to be measured with good enough fidelity that delensing should have a non-negligible impact on these parameter constraints.
